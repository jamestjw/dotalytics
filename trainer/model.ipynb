{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from google.cloud import bigquery, bigquery_storage_v1beta1, storage\n",
    "from google import auth\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json \n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google.cloud.bigquery extension is already loaded. To reload it, use:\n",
      "  %reload_ext google.cloud.bigquery\n"
     ]
    }
   ],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../Credentials/bigquery.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "    print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "Select *, ARRAY_LENGTH(picks_bans) as count\n",
    "from dota.dota_mini\n",
    "where ARRAY_LENGTH(picks_bans) > 0\n",
    "LIMIT 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery hero\n",
    "Select *\n",
    "from dota.hero_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hero['hero_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bigquery un_df\n",
    "#     Select dm.match_id\n",
    "#     from dota.dota_mini dm\n",
    "#     CROSS JOIN UNNEST(pickS_bans) as picks\n",
    "#     LIMIT 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_picks(current, sequence):\n",
    "    encoder = [int(x) for x in sequence[current:]] + [-1] * (current)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sequence, maxlen,padding='pre',value=0.0):\n",
    "    if len(sequence) >= maxlen:\n",
    "        return sequence[:maxlen]\n",
    "    else:\n",
    "        num_pad = maxlen - len(sequence)\n",
    "        pad_array = [value] * num_pad\n",
    "        if padding == 'pre':\n",
    "            return pad_array + sequence\n",
    "        elif padding == 'post':\n",
    "            return sequence + pad_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_training(sequence,maxlen=21, is_pad = True):\n",
    "    y = []\n",
    "    hero     = padding( [s['hero_id'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.)\n",
    "    pick_ban = padding( [int(s['is_pick']) for s in sequence ], maxlen=maxlen, padding='post',value=-1.)\n",
    "    team     = padding( [int(s['team']) for s in sequence    ], maxlen=maxlen,padding = 'post',value=-1.)\n",
    "\n",
    "#     hero     = padding( [s['hero_id'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.) if is_pad else [ s['hero_id'] for s in sequence]\n",
    "#     pick_ban = padding( [s['is_pick'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.) if is_pad else [ s['is_pick'] for s in sequence]\n",
    "#     pick_ban = padding( [s['is_pick'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.) if is_pad else [ s['is_pick'] for s in sequence]\n",
    "\n",
    "    placeholder = np.array([np.array([hero[i] ] + encode_picks(i, pick_ban) + encode_picks(i,team)) for i in range(maxlen)])\n",
    "    x = placeholder[:-1]\n",
    "    y = placeholder[:1,0]\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "\n",
    "def process_hero(sequence):\n",
    "    x        = [sequence[i]['hero_id'] for i in range(len(sequence)-1)]\n",
    "    y        = [sequence[i]['hero_id'] for i in range(1,len(sequence))]\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(data):\n",
    "#     train, test = train_test_split(data)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for t in tqdm(data):\n",
    "        x,y = process_training(t)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, list_of_sequence :list,pad: bool = True, shuffle:bool = True,batch_size=10):\n",
    "        self.list_of_sequence = np.random.shuffle(list_of_sequence) if shuffle else list_of_sequence\n",
    "        self.pad = pad\n",
    "        self.batch_size = 10\n",
    "        \n",
    "    def padding(self, sequence, maxlen,padding='pre',value=0.0):\n",
    "        if len(sequence) >= maxlen:\n",
    "            return sequence[:maxlen]\n",
    "        else:\n",
    "            num_pad = maxlen - len(sequence)\n",
    "            pad_array = [value] * num_pad\n",
    "            if padding == 'pre':\n",
    "                return pad_array + sequence\n",
    "            elif padding == 'post':\n",
    "                return sequence + pad_array\n",
    "            \n",
    "    def encode_pick(self. current, sequence):\n",
    "        encoder = [int(x) for x in sequence[current:]] + [-1] * (current)\n",
    "        return encoder\n",
    "\n",
    "            \n",
    "    def __len__(self): return len(self.list_of_sequence)\n",
    "                \n",
    "    def process_training(self,sequence,maxlen=21, is_pad = True):\n",
    "        x, y = [], []\n",
    "        \n",
    "#         hero     = padding( [s['hero_id'] for s in sequence] ,maxlen=maxlen,padding='post',value=0)\n",
    "#         pick_ban = padding( [int(s['is_pick']) for s in sequence ], maxlen=maxlen, padding='post',value=-1.)\n",
    "#         team     = padding( [int(s['team']) for s in sequence    ], maxlen=maxlen,padding = 'post',value=-1.)\n",
    "\n",
    "        hero     = padding( [s['hero_id'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.) if is_pad else [ s['hero_id'] for s in sequence]\n",
    "        pick_ban = padding( [s['is_pick'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.) if is_pad else [ s['is_pick'] for s in sequence]\n",
    "        team     = padding( [s['team'] for s in sequence] ,maxlen=maxlen,padding='post',value=-1.)    if is_pad else [ s['team'] for s in sequence]\n",
    "\n",
    "        placeholder = np.array([np.array([hero[i] ] + encode_picks(i, pick_ban) + encode_picks(i,team)) for i in range(maxlen)])\n",
    "        x = placeholder[:-1]\n",
    "        y = placeholder[1:,0]\n",
    "        return x,y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        total_batches = len(self) // self.batch_size\n",
    "        for i in range(total_batches):\n",
    "            seq =  [ self.process_training(arr) for arr in self.list_of_sequence[i*self.batch_size: (i+1)*self.batch_size] ]\n",
    "            x,y = zip(*seq)\n",
    "            yield np.array(x), np.array(y)\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df['picks_bans'][:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_t(sequence):\n",
    "    hero = [s['hero_id'] for s in sequence]\n",
    "    pick_ban = [int(s['is_pick']) for s in sequence ]\n",
    "    team = [int(s['team']) for s in sequence    ]\n",
    "    placeholder = np.array([np.array([hero[i] ] + encode_picks(i, pick_ban) + encode_picks(i,team)) for i in range(len(sequence))])\n",
    "    x = placeholder[:-1]\n",
    "    y = placeholder[1:,0]\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 33)\n",
      "(14, 31)\n",
      "(16, 35)\n",
      "(17, 37)\n",
      "(17, 37)\n",
      "(17, 37)\n",
      "(20, 43)\n",
      "(18, 39)\n",
      "(20, 43)\n",
      "(20, 43)\n"
     ]
    }
   ],
   "source": [
    "test = df['picks_bans'][:10].values\n",
    "mylist = []\n",
    "for i in test:\n",
    "    x,y = p_t(i)\n",
    "    mylist.append(x)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ['this','is','cat']\n",
    "# arr[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for seq in df['picks_bans']:\n",
    "        x,y = process_training(seq)\n",
    "        yield x,y\n",
    "        next\n",
    "        \n",
    "def generator_1(seq):\n",
    "    for s in seq:\n",
    "        x,y = process_training(s)\n",
    "        yield x,y\n",
    "        next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = generator_1(df['picks_bans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 138661.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tr0 = []\n",
    "target1 = []\n",
    "for seq in tqdm(df['picks_bans']):\n",
    "    x,y = process_hero(seq)\n",
    "    tr0.append(x)\n",
    "    target1.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr01 = tf.keras.preprocessing.sequence.pad_sequences(tr0,maxlen=21,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd1 = tf.data.Dataset.from_generator(generator=partial(MyGenerator,df['picks_bans']),output_types=( tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tfd1.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential( [\n",
    "        tf.keras.layers.LSTM(units=100,input_shape=(20,43),return_sequences=True),\n",
    "        tf.keras.layers.Dense(130)\n",
    "#         tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(130))\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=[tf.keras.losses.sparse_categorical_crossentropy],metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "# model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(tfd1,epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
